---
title: "Blocking strategies"
description: "Block inputs before the LLM or outputs after the LLM using /guard."
---

There are two common ways to integrate **/guard**:

### 1) Pre-LLM (block input)

- Send the **user message** to `/api/v1/guard` **before** calling your LLM provider.
- If `flagged: true`, **block** or **sanitize** the input and show a user-friendly message.
- If not flagged, forward the original message to the LLM.

```mermaid
flowchart LR
U[User] -->|message| G[/SageXAI /guard/]
G -->|flagged?| D{flagged}
D -- yes --> B[Block or sanitize]
D -- no --> L[Call LLM API]
```

### 2) Post-LLM (block output)

- Call your LLM provider first.
- Send the **LLM output** to `/api/v1/guard`.
- If `flagged: true`, **block** returning the output and show a safe alternative.

```mermaid
flowchart LR
U[User] --> L[Call LLM API]
L --> O[Model output]
O --> G[/SageXAI /guard/]
G -->|flagged?| D{flagged}
D -- yes --> B[Block response]
D -- no --> R[Return output]
```

SageXAI does not automatically block requests. You decide how to handle `flagged` results (block, sanitize, route to a human, etc.).
