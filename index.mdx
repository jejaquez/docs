---
title: "SageXAI â€” API-first AI Safety"
description: "Documentation for SageXAI's /guard endpoint and usage examples."
---

# Welcome to SageXAI

SageXAI is an API-first safety layer for LLMs. The **/guard** endpoint scans prompts and model outputs for risky patterns (e.g., jailbreak attempts, Unicode homoglyphs, data exfiltration cues) using our OWASP GenAI policy set.

- **Quickstart**: Create a token, send your first scan, and interpret the response.
- **API: /guard**: Request/response schema with examples.
- **API: /guard/results**: Retrieve historical scan results.
